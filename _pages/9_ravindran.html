<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!-- saved from url=(0069)http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning.html -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">



<title>Balaraman Ravindran</title>
<meta name="keywords" content="">
<meta name="description" content="">
<link href="./Balaraman Ravindran_files/default.css" rel="stylesheet" type="text/css">
</head><body>
<div id="header">
<center>
	<div id="logo">
		<!--<h1>Balaraman Ravindran</h1>-->
	<a href="http://www.cse.iitm.ac.in/~ravi/Ravi-Pic.jpg"><img src="./Balaraman Ravindran_files/Ravi-Pic-small.jpg" vspace="25" height="150" align="middle"></a>
	</div>
</center>
	<div id="address">
<font size="+2">Balaraman Ravindran</font><br>
<!--BSB 349--><br>
Computer Science and Engineering &amp;<br>
Robert Bosch Centre for Data Science and AI<br>
Indian Institute of Technology Madras<br>
Chennai, 600 036.<br>
Ph: +91-44-22574370<br>
ravi@cse.iitm.ac.in<br>
		<ul>
			<li><a href="http://www.cse.iitm.ac.in/~ravi/index.html" accesskey="1" title="">Home</a></li>
			<li><a href="http://www.cse.iitm.ac.in/~ravi/publications.html" accesskey="2" title="">Publications</a></li>
			<li><a href="http://www.cse.iitm.ac.in/~ravi/research.html" accesskey="3" title="">Research</a></li>
			<li><a href="http://www.cse.iitm.ac.in/~ravi/teaching.html" accesskey="4" title="">Teaching</a></li>
			<li><a href="http://www.cse.iitm.ac.in/~ravi/students.html" accesskey="5" title="">Students</a></li>
		</ul>
	</div>
</div>
<div id="content">
	<div id="colOne">
		<div class="content">
<h4><a href="http://www.cse.iitm.ac.in/~ravi/courses/index.html">Online NPTEL Courses</a></h4>		<!-- replace with web link -->
(<font size="1"><a href="http://www.cse.iitm.ac.in/~ravi/teaching.html">Classroom Courses Taught</a></font>)<br>
<ul>
<h4>Reinforcment Learning</h4><p></p>
Reinforcement learning is a paradigm that aims to model the 
trial-and-error learning process that is needed in many problem 
situations where explicit instructive signals are not available. It has 
roots in operations research, behavioral psychology and AI. The goal of 
the course is to introduce the basic mathematical foundations of 
reinforcement learning, as well as highlight some of the recent 
directions of research.
<br>
<font size="1">Previously offered: <a href="http://nptel.ac.in/courses/106106143/">July-October 2016</a>.</font>

<font size="2"><ul>
	<li><p><b>Week 0 - Preparatory Material</b></p></li>
		<ul>
			<img src="/assets/youtube.jpg" alt="youtube video" style="width:20px;height:20px;"> &nbsp;&nbsp; <a href="https://youtu.be/4CgVEt-BhLA">Probability tutorial - 1</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="/assets/videoken.jpg" alt="videoken video" style="width:20px;height:20px;"> &nbsp;&nbsp; <a href="https://videoken.com/embed/6KBUU2Aa6lw">Probability tutorial - 1</a>

			<li>&nbsp;&nbsp; <a href="https://youtu.be/NFQ94cd649M">Probability tutorial - 2</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/lWSYxvJbf9E">Linear algebra tutorial - 1</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/wW4tIx9dOk8">Linear algebra tutorial - 2</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Assignment0.pdf">Assignment 0</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Solution0.pdf">Solution 0</a></li>
		</ul>
	<li><p><b>Week 1 - Introduction to RL and Immediate RL</b></p></li>
		<ul>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/YaPSPu7K9S0">Introduction to RL</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/ewkm38skUlY">RL framework and applications</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/nNK4xKkAapM">Introduction to immediate RL</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/AizR8uvhX-s">Bandit optimalities</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/iB4m-jP7blI">Value function based methods</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Assignment1.pdf">Assignment 1</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Solution1.pdf">Solution 1</a></li>
		</ul>
	<li><p><b>Week 2 - Bandit Algorithms</b></p></li>
		<ul>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/TIlDzLZPyhY">UCB 1</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/KB-ZDvLbuOQ">Concentration bounds</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/7IA6Zb7KZM0">UCB 1 Theorem</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/N_9HgdhXKIY">PAC bounds</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/3iNaR0Mq1ug">Median elimination</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/H2OWTxdauqA">Thompson sampling</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Assignment2.pdf">Assignment 2</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Solution2.pdf">Solution 2</a></li>
			<li>&nbsp;&nbsp; <a href="https://drive.google.com/open?id=1Cx5BGNvLOLorIuvdvg3jyWJ476SN9V7H">Auer, P.; Cesa-Bianchi, N.; Fischer, P. 2002. Finite-time Analysis of the Multiarmed Bandit Problem.</a></li>
			<li>&nbsp;&nbsp; <a href="https://drive.google.com/open?id=1w3NAfjO96-1290AYBgxH1L5V00RjMFMJ">Auer, P.; Ortner, R. 2010. UCB Revisited: Improved Regret Bounds for the Stochastic Multi-Armed Bandit Problem.</a></li>
			<li>&nbsp;&nbsp; <a href="https://drive.google.com/open?id=1hY0U7ZM7qKDaNQyaUv_nFiA2serg9arb">Even-Dar, E.; Mannor, S.; Mansour, Y. 2006. Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems.</a></li>
			<li>&nbsp;&nbsp; Tutorial on OFUL (Szepesvari, C.) <a href="https://www.youtube.com/watch?v=VVcLnAoU9Gw">Part 1</a> <a href="https://www.youtube.com/watch?v=cknukHreMdI">Part 2</a> <a href="https://www.youtube.com/watch?v=ruIO79C2IQc">Part 3</a></li>
		</ul>
	<li><p><b>Week 3 - Policy Gradient Methods &amp; Introduction to Full RL</b></p></li>
		<ul>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/y3QEOmkxsQo">Policy search</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/WIBWQ7lOXoA">REINFORCE</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/K2Hh-ayvsJU">Contextual bandits</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/yIdgKWFulNQ">Full RL introduction</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/BiY_X1c068U">Returns, value functions &amp; MDPs</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Assignment3.pdf">Assignment 3</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Solution3.pdf">Solution 3</a></li>
			<li>&nbsp;&nbsp; <a href="https://drive.google.com/open?id=1Z4koDFo3jS1Y_u9ddzqLr0gd1_7h467v">Notes on REINFORCE algorithm</a></li>
		</ul>
	<li><p><b>Week 4 - MDP Formulation, Bellman Equations &amp; Optimality Proofs</b></p></li>
		<ul>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/BpSNh1h4HeQ">MDP modelling</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/CTPHADvQxSs">Bellman equation</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/4S9aRrsP954">Bellman optimality equation</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/THmztE-ghWc">Cauchy sequence &amp; Green's equation</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/EKwc7rw9YCU">Banach fixed point theorem</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/9UhK8U6rEVY">Convergence proof</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Assignment4.pdf">Assignment 4</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Solution4.pdf">Solution 4</a></li>
		</ul>
	<li><p><b>Week 5 - Dynamic Programming &amp; Monte Carlo Methods</b></p></li>
		<ul>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/ybEyXc4hNuk">LPI convergence</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/F3DjpixO1bY">Value iteration</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/09L0nqw9Vnc">Policy iteration</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/_0BQZyXx0eU">Dynamic programming</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/DaxOiIdjQ4Y">Monte Carlo</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/h7lfqnV-8Pc">Control in Monte Carlo</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Assignment5.pdf">Assignment 5</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Solution5.pdf">Solution 5</a></li>
		</ul>
	<li><p><b>Week 6 - Monte Carlo &amp; Temporal Difference Methods</b></p></li>
		<ul>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/oHE7u15n7Qg">Off Policy MC</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/unCdZCQS64g">UCT</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/4KlVxH8wMWQ">TD(0)</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/x3PgPnVC-bQ">TD(0) control</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/ioQz9Pkycb0">Q-learning</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/w3wGvwi336I">Afterstate</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Assignment6.pdf">Assignment 6</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Solution6.pdf">Solution 6</a></li>
		</ul>
	<li><p><b>Week 7 - Eligibility Traces</b></p></li>
		<ul>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/n0K83V1sCxc">Eligibility traces</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/A1s3dc64uhE">Backward view of eligibility traces</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/OgKysheQJSQ">Eligibility trace control</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/uGUAUkmqQtk">Thompson sampling recap</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Assignment7.pdf">Assignment 7</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Solution7.pdf">Solution 7</a></li>
		</ul>
	<li><p><b>Week 8 - Function Approximation</b></p></li>
		<ul>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/gqSuPgrcVx8">Function approximation</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/c4cvheE3diA">Linear parameterization</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/wGPxro6C2ik">State aggregation methods</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/N21zCqTwxbs">Function approximation &amp; eligibility traces</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/zTFNYrYbvVE">LSTD &amp; LSTDQ</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/JmbN6XZ4Cro">LSPI &amp; Fitted Q</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Assignment8.pdf">Assignment 8</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Solution8.pdf">Solution 8</a></li>
		</ul>
	<li><p><b>Week 9 - DQN, Fitted Q &amp; Policy Gradient Approaches</b></p></li>
		<ul>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/AohtWrJwvgg">DQN &amp; Fitted Q-iteration</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/f2l8bv8GH5U">Policy gradient approach</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/sTZ4GyJ4FZU">Actor critic &amp; REINFORCE</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/BEhnse8cLDw">REINFORCE (cont'd)</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/X6yCRaQa5FE">Policy gradient with function approximation</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Assignment9.pdf">Assignment 9</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Solution9.pdf">Solution 9</a></li>
			<li>&nbsp;&nbsp; <a href="https://drive.google.com/open?id=1C8jVxnURRovcQEHgxq2kH1KVufIxvbRT">Notes on Policy Gradient Algorithms</a></li>
		</ul>
	<li><p><b>Week 10 - Hierarchical Reinforcement Learning</b></p></li>
		<ul>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/K5MlmO0UJtI">Hierarchical reinforcement learning</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/EbTIQqVDJsg">Types of optimality</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/vdRG-EbcNGw">Semi-Markov decision processes</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/1eb4vECGKC4">Options</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/6wH3yS07NTA">Learning with options</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/rVhb6f6G-1M">Hierarchical abstract machines</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Assignment10.pdf">Assignment 10</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Solution10.pdf">Solution 10</a></li>
			<li>&nbsp;&nbsp; <a href="http://www-anw.cs.umass.edu/pubs/2003/barto_m_DEDS03.pdf">Barto, A. G.; Mahadevan, S. 2003. Recent Advances in Hierarchical Reinforcement Learning.</a></li>
		</ul>
	<li><p><b>Week 11 - Hierarchical RL: MAXQ</b></p></li>
		<ul>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/4mmW0kYmK3I">MAXQ</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/1iACStiJQBs">MAXQ value function decomposition</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/uJ0oNtDG6ro">Option discovery</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Assignment11.pdf">Assignment 11</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Solution11.pdf">Solution 11</a></li>
			<li>&nbsp;&nbsp; <a href="https://arxiv.org/pdf/cs/9905014.pdf">Dietterich, T. G. 2000. Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition.</a></li>
		</ul>
	<li><p><b>Week 12 - POMDPs</b></p></li>
		<ul>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/9G_KevA8DFY">POMDP introduction</a></li>
			<li>&nbsp;&nbsp; <a href="https://youtu.be/dMOUp7YzUpQ">Solving POMDP</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Assignment12.pdf">Assignment 12</a></li>
			<li>&nbsp;&nbsp; <a href="http://www.cse.iitm.ac.in/~ravi/courses/Reinforcement%20Learning_files/Solution12.pdf">Solution 12</a></li>
			<li>&nbsp;&nbsp; <a href="http://cs.brown.edu/research/ai/pomdp/tutorial/">POMDP Tutorial</a></li>
			<li>&nbsp;&nbsp; <a href="https://www.youtube.com/watch?v=EdBYYXSFt7k">Tutorial on Predictive State Representations (Singh, S. P.)</a></li>
		</ul>
</ul></font>

</ul>
</div> </div> <div id="colTwo"> 
               <h4 class="top-head">Currently Teaching</h4>
                <div class="content">
                <p>
                </p><ul>                
		<font size="2"><li> <a href="https://onlinecourses.nptel.ac.in/noc17_mg24/preview">Introduction to Data Analytics</a></li></font>

                <div class="content">
</div>
			<div class="content"><form method="get" action="http://www.google.com/search"> <input name="q" size="17" maxlength="255" type="text"> <input name="btnG" value="Google Search" type="submit"> </form></div>
<font size="1">	</font></ul></div><font size="2">
</font></div><font size="2">
<div id="footer" style="clear: both;">
<font size="1">	</font><p><font size="1">Copyright 2009 Balaraman Ravindran. Designed based on a template by  <a href="http://freecsstemplates.org/"><strong>Free CSS Templates</strong></a> and <a href="http://people.csail.mit.edu/kersting/index.html">Kristian Kersting</a></font></p>
</div>

</font>
</div>

</body></html>
